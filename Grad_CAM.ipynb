{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=7,stride=1,padding=3, padding_mode='zeros')\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=5, stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, stride=2)\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,kernel_size=2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x,kernel_size=2)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def train(model, train_loader,valid_loader, optimizer, criterion, device,epochs = 10):\n",
    "    model.train()\n",
    "    history = {'train':{'loss':[],'accuracy':[]}, 'valid':{'loss':[],'accuracy':[]}}\n",
    "    n = len(train_loader)\n",
    "    for epoch in trange(epochs):\n",
    "        Loss_epoch = 0\n",
    "        for idx, data in enumerate(train_loader):\n",
    "            input, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # Loss_epoch += loss.item()\n",
    "        # Loss_history.append(Loss_epoch/n)\n",
    "        evaluation_train = evaluate(model, train_loader,criterion, device)\n",
    "        evaluation_valid = evaluate(model, valid_loader,criterion, device)\n",
    "        history['train']['accuracy'].append(evaluation_train['accuracy'])\n",
    "        history['train']['loss'].append(evaluation_train['loss'])\n",
    "\n",
    "        history['valid']['loss'].append(evaluation_valid['loss'])\n",
    "        history['valid']['accuracy'].append(evaluation_valid['accuracy'])\n",
    "    return history\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = torch.max(output, dim=1)\n",
    "    return torch.mean(preds == labels).item()\n",
    "\n",
    "def evaluate(model,data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    Accuracy_history = []\n",
    "    Loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(data_loader):\n",
    "            input, target = data[0].to(device), data[1].to(device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            Accuracy_history.append(accuracy(output, target))\n",
    "            Loss_history.append(loss.item())\n",
    "    return {'accuracy': torch.mean(Accuracy_history).item(), 'loss': torch.mean(Loss_history).item()}\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "model = resnet50(pretrained=True)\n",
    "target_layers = [model.layer4[-1]]\n",
    "input_tensor = # Create an input tensor image for your model..\n",
    "# Note: input_tensor can be a batch tensor with several images!\n",
    "\n",
    "# Construct the CAM object once, and then re-use it on many images:\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "# You can also use it within a with statement, to make sure it is freed,\n",
    "# In case you need to re-create it inside an outer loop:\n",
    "# with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "#   ...\n",
    "\n",
    "# We have to specify the target we want to generate\n",
    "# the Class Activation Maps for.\n",
    "# If targets is None, the highest scoring category\n",
    "# will be used for every image in the batch.\n",
    "# Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
    "# That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
    "\n",
    "targets = [ClassifierOutputTarget(281)]\n",
    "\n",
    "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "\n",
    "# In this example grayscale_cam has only one image in the batch:\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "# You can also get the model outputs without having to re-inference\n",
    "model_outputs = cam.outputs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
